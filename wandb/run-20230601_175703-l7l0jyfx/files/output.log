C:\Users\tripats\.conda\envs\uavenv\lib\site-packages\torch\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\TensorShape.cpp:2895.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
0
[0, 0, 0, 4, 2]
Number of user connected in  0  episode is:  [4 0 0 4 4]
Total user connected in  0  episode is:  12
1
2
3
4
C:\Users\tripats\.conda\envs\uavenv\lib\site-packages\numpy\core\shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  ary = asanyarray(ary)
C:\Users\tripats\.conda\envs\uavenv\lib\site-packages\torch\nn\modules\loss.py:922: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 512])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
5
6
7
8
9
10
[0, 0, 0, 0, 0]
Number of user connected in  10  episode is:  [ 4  0  0 12  0]
Total user connected in  10  episode is:  16
11
12
13
14
15
16
17
18
19
20
[0, 0, 0, 0, 4]
Number of user connected in  20  episode is:  [3 0 0 6 0]
Total user connected in  20  episode is:  9
21
22
23
24
25
26
27
28
29
30
[0, 0, 1, 0, 0]
Number of user connected in  30  episode is:  [4 0 3 0 0]
Total user connected in  30  episode is:  7
31
32
33
34
Traceback (most recent call last):
  File "C:\Users\tripats\Documents\GitHub\uav_nw_correlated_dql_connectivity\main.py", line 470, in <module>
    UAV_OB[k].train(batch_size, dnn_epoch)
  File "C:\Users\tripats\Documents\GitHub\uav_nw_correlated_dql_connectivity\main.py", line 249, in train
    loss.backward()
  File "C:\Users\tripats\.conda\envs\uavenv\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\tripats\.conda\envs\uavenv\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt